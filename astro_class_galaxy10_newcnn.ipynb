{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48PHZXDvAHbI",
        "outputId": "9f872b44-5671-43fa-ca42-28177e698196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-visualizer\n",
            "  Downloading keras_visualizer-2.4-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: keras-visualizer\n",
            "Successfully installed keras-visualizer-2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-visualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2roKiuwkws0",
        "outputId": "1fd49d25-e244-4c34-96b8-56ead7ffe1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting astroNN\n",
            "  Downloading astroNN-1.0.1.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from astroNN) (1.21.6)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.7/dist-packages (from astroNN) (4.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from astroNN) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from astroNN) (3.2.2)\n",
            "Collecting astroquery\n",
            "  Downloading astroquery-0.4.6-py3-none-any.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from astroNN) (1.3.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from astroNN) (0.11.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from astroNN) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from astroNN) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from astroNN) (21.3)\n",
            "Requirement already satisfied: pyerfa>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from astropy->astroNN) (2.0.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from astropy->astroNN) (4.11.3)\n",
            "Requirement already satisfied: html5lib>=0.999 in /usr/local/lib/python3.7/dist-packages (from astroquery->astroNN) (1.0.1)\n",
            "Collecting pyvo>=1.1\n",
            "  Downloading pyvo-1.2.1-py3-none-any.whl (832 kB)\n",
            "\u001b[K     |████████████████████████████████| 832 kB 40.8 MB/s \n",
            "\u001b[?25hCollecting keyring>=4.0\n",
            "  Downloading keyring-23.5.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from astroquery->astroNN) (4.6.3)\n",
            "Requirement already satisfied: requests>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from astroquery->astroNN) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib>=0.999->astroquery->astroNN) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib>=0.999->astroquery->astroNN) (0.5.1)\n",
            "Collecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->astropy->astroNN) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->astropy->astroNN) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.3->astroquery->astroNN) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.3->astroquery->astroNN) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.3->astroquery->astroNN) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.3->astroquery->astroNN) (2.10)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery->astroNN) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery->astroNN) (2.21)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->astroNN) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->astroNN) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->astroNN) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->astroNN) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->astroNN) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astroNN) (2022.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->astroNN) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->astroNN) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->astroNN) (3.1.0)\n",
            "Building wheels for collected packages: astroNN\n",
            "  Building wheel for astroNN (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for astroNN: filename=astroNN-1.0.1-py3-none-any.whl size=9284595 sha256=aeb8e7b4748670e240ea943f6cbb09590d1c787ebc6306a7fa1efecc49bb6a79\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/a4/7e/4cbf2a7f9cd51929da9d09345e8cd37c647b54825a1314dd2d\n",
            "Successfully built astroNN\n",
            "Installing collected packages: jeepney, cryptography, SecretStorage, pyvo, keyring, astroquery, astroNN\n",
            "Successfully installed SecretStorage-3.3.2 astroNN-1.0.1 astroquery-0.4.6 cryptography-37.0.2 jeepney-0.8.0 keyring-23.5.0 pyvo-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install astroNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHWB5fGxANEn"
      },
      "outputs": [],
      "source": [
        "from keras_visualizer import visualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bFOQ930kK-V",
        "outputId": "5f8408a4-421b-470a-81db-a277332cc863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING! APOGEE environment variable SDSS_LOCAL_SAS_MIRROR not set\n",
            "WARNING! Gaia environment variable GAIA_TOOLS_DATA not set\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import layers\n",
        "from astroNN.datasets import load_galaxy10\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from astroNN.datasets.galaxy10 import galaxy10cls_lookup\n",
        "from PIL import Image as im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT8SrAnGY2L8",
        "outputId": "c2e96723-87d7-411f-c723-359a45b9b419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Galaxy10.h5:  99%|█████████▉| 209M/210M [00:03<00:00, 75.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Galaxy10 successfully to /root/.astroNN/datasets/Galaxy10.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGalaxy10.h5: 210MB [00:05, 38.6MB/s]                           \n"
          ]
        }
      ],
      "source": [
        "#Load Data\n",
        "dataset = load_galaxy10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC6QCN3gY3tk"
      },
      "outputs": [],
      "source": [
        "images, labels = dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7hbHln_5bjA-",
        "outputId": "371c253c-d7a8-4e19-b764-2c59a63f2bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(69, 69, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f796d14a490>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(images[0].shape)\n",
        "first_image = im.fromarray(images[0])\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(first_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehGKpXwdFl9z"
      },
      "outputs": [],
      "source": [
        "#Remove low count classes\n",
        "del_idx = []\n",
        "\n",
        "for idx, label in enumerate(labels):\n",
        "  if (label in [3,5,6,8,9]): del_idx.append(idx)\n",
        "\n",
        "labels = np.delete(labels, del_idx)\n",
        "images = np.delete(images, del_idx, 0)\n",
        "labels = np.where(labels == 4, 3, labels)\n",
        "labels = np.where(labels == 7, 4, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k33wFgUGpB-x"
      },
      "outputs": [],
      "source": [
        "labels = utils.to_categorical(labels, 5)\n",
        "labels = labels.astype(np.float32)\n",
        "images = images.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZADS9QjHP0JM",
        "outputId": "b5592409-197a-4a72-a1f8-fd7635c15dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19405, 5)\n"
          ]
        }
      ],
      "source": [
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2-fEOo2Fm5M"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "train_idx, val_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.2)\n",
        "train_ds, train_labels, val_ds, val_labels = images[train_idx], labels[train_idx], images[val_idx], labels[val_idx]\n",
        "val_img = val_ds\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_ds, train_labels)).batch(128)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_ds, val_labels)).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-5qtrDyFz8U",
        "outputId": "2a31034a-6f86-4234-cb2f-355fcec8b23b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Disk, Face-on, No Spiral', 'Smooth, Completely round', 'Disk, Edge-on, Rounded Bulge', 'Disk, Face-on, Tight Spiral']\n"
          ]
        }
      ],
      "source": [
        "# Lookup class labels\n",
        "class_names = []\n",
        "for i in [0,1,2,4,7]:\n",
        "  class_names.append(galaxy10cls_lookup(i))\n",
        "print(class_names)\n",
        "num_classes = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqCh7lCFocgf"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29pD1qxRoPTo"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.3, fill_mode='nearest', interpolation='bilinear', seed=None, fill_value=0.0)\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7A3YI-rZgKb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rdhwd7iF4IT"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    data_augmentation,\n",
        "    tf.keras.Input(shape=(69, 69, 3)),\n",
        "    layers.Conv2D(32, kernel_size=7, strides=2, padding=\"same\"),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.LeakyReLU(alpha=0.4),\n",
        "    layers.Conv2D(32, kernel_size=7, strides=2, padding=\"same\"),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.LeakyReLU(alpha=0.4),\n",
        "    layers.Conv2D(64, kernel_size=7, strides=2, padding=\"same\"),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.LeakyReLU(alpha=0.4),\n",
        "    layers.Conv2D(128, kernel_size=7, strides=2, padding=\"same\"),\n",
        "    layers.LeakyReLU(alpha=0.4),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(5, activation=\"sigmoid\"),\n",
        "  ])\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "    \n",
        "  )\n",
        "  return model\n",
        "model = create_model()\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFiLkKp8F7Og",
        "outputId": "5bcf9183-1d0c-49e0-9957-41c00b98b2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "122/122 [==============================] - 17s 38ms/step - loss: 1.4753 - accuracy: 0.3216 - val_loss: 1.3401 - val_accuracy: 0.4058\n",
            "Epoch 2/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 1.3446 - accuracy: 0.3891 - val_loss: 1.2728 - val_accuracy: 0.4200\n",
            "Epoch 3/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 1.2781 - accuracy: 0.4125 - val_loss: 1.2016 - val_accuracy: 0.4553\n",
            "Epoch 4/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 1.2107 - accuracy: 0.4516 - val_loss: 1.1314 - val_accuracy: 0.5024\n",
            "Epoch 5/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 1.1436 - accuracy: 0.5018 - val_loss: 1.0632 - val_accuracy: 0.5527\n",
            "Epoch 6/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 1.0805 - accuracy: 0.5413 - val_loss: 0.9969 - val_accuracy: 0.6011\n",
            "Epoch 7/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 1.0272 - accuracy: 0.5796 - val_loss: 0.9412 - val_accuracy: 0.6390\n",
            "Epoch 8/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.9745 - accuracy: 0.6085 - val_loss: 0.8931 - val_accuracy: 0.6632\n",
            "Epoch 9/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.9324 - accuracy: 0.6303 - val_loss: 0.8519 - val_accuracy: 0.6746\n",
            "Epoch 10/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8876 - accuracy: 0.6527 - val_loss: 0.8214 - val_accuracy: 0.6949\n",
            "Epoch 11/400\n",
            "122/122 [==============================] - 5s 37ms/step - loss: 0.8642 - accuracy: 0.6641 - val_loss: 0.7907 - val_accuracy: 0.7021\n",
            "Epoch 12/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8366 - accuracy: 0.6755 - val_loss: 0.7645 - val_accuracy: 0.7137\n",
            "Epoch 13/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8109 - accuracy: 0.6847 - val_loss: 0.7507 - val_accuracy: 0.7186\n",
            "Epoch 14/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7921 - accuracy: 0.6909 - val_loss: 0.7266 - val_accuracy: 0.7230\n",
            "Epoch 15/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7708 - accuracy: 0.7019 - val_loss: 0.7163 - val_accuracy: 0.7269\n",
            "Epoch 16/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7583 - accuracy: 0.7083 - val_loss: 0.7103 - val_accuracy: 0.7297\n",
            "Epoch 17/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7432 - accuracy: 0.7159 - val_loss: 0.6933 - val_accuracy: 0.7325\n",
            "Epoch 18/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7361 - accuracy: 0.7126 - val_loss: 0.6845 - val_accuracy: 0.7418\n",
            "Epoch 19/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7277 - accuracy: 0.7150 - val_loss: 0.6789 - val_accuracy: 0.7382\n",
            "Epoch 20/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7192 - accuracy: 0.7224 - val_loss: 0.6657 - val_accuracy: 0.7475\n",
            "Epoch 21/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7027 - accuracy: 0.7266 - val_loss: 0.6599 - val_accuracy: 0.7470\n",
            "Epoch 22/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6944 - accuracy: 0.7303 - val_loss: 0.6516 - val_accuracy: 0.7511\n",
            "Epoch 23/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6919 - accuracy: 0.7304 - val_loss: 0.6437 - val_accuracy: 0.7532\n",
            "Epoch 24/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6825 - accuracy: 0.7330 - val_loss: 0.6388 - val_accuracy: 0.7555\n",
            "Epoch 25/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6817 - accuracy: 0.7325 - val_loss: 0.6354 - val_accuracy: 0.7539\n",
            "Epoch 26/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6713 - accuracy: 0.7416 - val_loss: 0.6302 - val_accuracy: 0.7588\n",
            "Epoch 27/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6704 - accuracy: 0.7411 - val_loss: 0.6318 - val_accuracy: 0.7578\n",
            "Epoch 28/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6599 - accuracy: 0.7416 - val_loss: 0.6211 - val_accuracy: 0.7653\n",
            "Epoch 29/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6519 - accuracy: 0.7454 - val_loss: 0.6164 - val_accuracy: 0.7686\n",
            "Epoch 30/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6518 - accuracy: 0.7470 - val_loss: 0.6134 - val_accuracy: 0.7650\n",
            "Epoch 31/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6452 - accuracy: 0.7474 - val_loss: 0.6064 - val_accuracy: 0.7704\n",
            "Epoch 32/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6403 - accuracy: 0.7506 - val_loss: 0.6096 - val_accuracy: 0.7691\n",
            "Epoch 33/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6378 - accuracy: 0.7470 - val_loss: 0.6018 - val_accuracy: 0.7735\n",
            "Epoch 34/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6275 - accuracy: 0.7548 - val_loss: 0.5947 - val_accuracy: 0.7781\n",
            "Epoch 35/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6275 - accuracy: 0.7558 - val_loss: 0.5952 - val_accuracy: 0.7743\n",
            "Epoch 36/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6272 - accuracy: 0.7566 - val_loss: 0.5891 - val_accuracy: 0.7797\n",
            "Epoch 37/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6258 - accuracy: 0.7559 - val_loss: 0.5944 - val_accuracy: 0.7756\n",
            "Epoch 38/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6151 - accuracy: 0.7593 - val_loss: 0.5839 - val_accuracy: 0.7805\n",
            "Epoch 39/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6174 - accuracy: 0.7588 - val_loss: 0.5829 - val_accuracy: 0.7802\n",
            "Epoch 40/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6144 - accuracy: 0.7552 - val_loss: 0.5794 - val_accuracy: 0.7828\n",
            "Epoch 41/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6096 - accuracy: 0.7619 - val_loss: 0.5754 - val_accuracy: 0.7830\n",
            "Epoch 42/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6064 - accuracy: 0.7634 - val_loss: 0.5784 - val_accuracy: 0.7833\n",
            "Epoch 43/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6066 - accuracy: 0.7647 - val_loss: 0.5749 - val_accuracy: 0.7818\n",
            "Epoch 44/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5989 - accuracy: 0.7666 - val_loss: 0.5694 - val_accuracy: 0.7864\n",
            "Epoch 45/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5959 - accuracy: 0.7678 - val_loss: 0.5655 - val_accuracy: 0.7867\n",
            "Epoch 46/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5908 - accuracy: 0.7681 - val_loss: 0.5671 - val_accuracy: 0.7897\n",
            "Epoch 47/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5904 - accuracy: 0.7675 - val_loss: 0.5641 - val_accuracy: 0.7885\n",
            "Epoch 48/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5950 - accuracy: 0.7673 - val_loss: 0.5614 - val_accuracy: 0.7885\n",
            "Epoch 49/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5859 - accuracy: 0.7711 - val_loss: 0.5598 - val_accuracy: 0.7887\n",
            "Epoch 50/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5863 - accuracy: 0.7715 - val_loss: 0.5596 - val_accuracy: 0.7934\n",
            "Epoch 51/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5800 - accuracy: 0.7687 - val_loss: 0.5542 - val_accuracy: 0.7946\n",
            "Epoch 52/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5765 - accuracy: 0.7754 - val_loss: 0.5559 - val_accuracy: 0.7936\n",
            "Epoch 53/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5795 - accuracy: 0.7718 - val_loss: 0.5515 - val_accuracy: 0.7941\n",
            "Epoch 54/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5696 - accuracy: 0.7795 - val_loss: 0.5514 - val_accuracy: 0.7941\n",
            "Epoch 55/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5721 - accuracy: 0.7767 - val_loss: 0.5514 - val_accuracy: 0.7939\n",
            "Epoch 56/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5692 - accuracy: 0.7778 - val_loss: 0.5518 - val_accuracy: 0.7967\n",
            "Epoch 57/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5689 - accuracy: 0.7772 - val_loss: 0.5442 - val_accuracy: 0.7972\n",
            "Epoch 58/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5686 - accuracy: 0.7787 - val_loss: 0.5465 - val_accuracy: 0.7972\n",
            "Epoch 59/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5626 - accuracy: 0.7813 - val_loss: 0.5477 - val_accuracy: 0.7985\n",
            "Epoch 60/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5625 - accuracy: 0.7825 - val_loss: 0.5435 - val_accuracy: 0.7975\n",
            "Epoch 61/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.5583 - accuracy: 0.7836 - val_loss: 0.5412 - val_accuracy: 0.7977\n",
            "Epoch 62/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5548 - accuracy: 0.7850 - val_loss: 0.5404 - val_accuracy: 0.7964\n",
            "Epoch 63/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.5543 - accuracy: 0.7838 - val_loss: 0.5373 - val_accuracy: 0.8042\n",
            "Epoch 64/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.5557 - accuracy: 0.7840 - val_loss: 0.5395 - val_accuracy: 0.8003\n",
            "Epoch 65/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5558 - accuracy: 0.7829 - val_loss: 0.5347 - val_accuracy: 0.8057\n",
            "Epoch 66/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5481 - accuracy: 0.7857 - val_loss: 0.5325 - val_accuracy: 0.8031\n",
            "Epoch 67/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5482 - accuracy: 0.7871 - val_loss: 0.5315 - val_accuracy: 0.8016\n",
            "Epoch 68/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5497 - accuracy: 0.7886 - val_loss: 0.5324 - val_accuracy: 0.8024\n",
            "Epoch 69/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5436 - accuracy: 0.7887 - val_loss: 0.5375 - val_accuracy: 0.7975\n",
            "Epoch 70/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5472 - accuracy: 0.7870 - val_loss: 0.5314 - val_accuracy: 0.8019\n",
            "Epoch 71/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5392 - accuracy: 0.7885 - val_loss: 0.5304 - val_accuracy: 0.8024\n",
            "Epoch 72/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5435 - accuracy: 0.7867 - val_loss: 0.5297 - val_accuracy: 0.8011\n",
            "Epoch 73/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5483 - accuracy: 0.7869 - val_loss: 0.5326 - val_accuracy: 0.8024\n",
            "Epoch 74/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5406 - accuracy: 0.7897 - val_loss: 0.5244 - val_accuracy: 0.8060\n",
            "Epoch 75/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5373 - accuracy: 0.7897 - val_loss: 0.5280 - val_accuracy: 0.8044\n",
            "Epoch 76/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5390 - accuracy: 0.7869 - val_loss: 0.5271 - val_accuracy: 0.8011\n",
            "Epoch 77/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5373 - accuracy: 0.7899 - val_loss: 0.5258 - val_accuracy: 0.8021\n",
            "Epoch 78/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5349 - accuracy: 0.7901 - val_loss: 0.5219 - val_accuracy: 0.8055\n",
            "Epoch 79/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5321 - accuracy: 0.7925 - val_loss: 0.5199 - val_accuracy: 0.8037\n",
            "Epoch 80/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5308 - accuracy: 0.7915 - val_loss: 0.5227 - val_accuracy: 0.8060\n",
            "Epoch 81/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5320 - accuracy: 0.7921 - val_loss: 0.5210 - val_accuracy: 0.8088\n",
            "Epoch 82/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5298 - accuracy: 0.7936 - val_loss: 0.5168 - val_accuracy: 0.8075\n",
            "Epoch 83/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5288 - accuracy: 0.7968 - val_loss: 0.5197 - val_accuracy: 0.8034\n",
            "Epoch 84/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5278 - accuracy: 0.7935 - val_loss: 0.5174 - val_accuracy: 0.8029\n",
            "Epoch 85/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5272 - accuracy: 0.7948 - val_loss: 0.5218 - val_accuracy: 0.8026\n",
            "Epoch 86/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5214 - accuracy: 0.7994 - val_loss: 0.5144 - val_accuracy: 0.8104\n",
            "Epoch 87/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5237 - accuracy: 0.7982 - val_loss: 0.5131 - val_accuracy: 0.8096\n",
            "Epoch 88/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5269 - accuracy: 0.7925 - val_loss: 0.5176 - val_accuracy: 0.8034\n",
            "Epoch 89/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5203 - accuracy: 0.7974 - val_loss: 0.5129 - val_accuracy: 0.8065\n",
            "Epoch 90/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5244 - accuracy: 0.7963 - val_loss: 0.5100 - val_accuracy: 0.8086\n",
            "Epoch 91/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5161 - accuracy: 0.7968 - val_loss: 0.5115 - val_accuracy: 0.8086\n",
            "Epoch 92/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5211 - accuracy: 0.7973 - val_loss: 0.5095 - val_accuracy: 0.8093\n",
            "Epoch 93/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5189 - accuracy: 0.7946 - val_loss: 0.5128 - val_accuracy: 0.8039\n",
            "Epoch 94/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5170 - accuracy: 0.7995 - val_loss: 0.5095 - val_accuracy: 0.8083\n",
            "Epoch 95/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5214 - accuracy: 0.7954 - val_loss: 0.5122 - val_accuracy: 0.8062\n",
            "Epoch 96/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5154 - accuracy: 0.7984 - val_loss: 0.5138 - val_accuracy: 0.8029\n",
            "Epoch 97/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5138 - accuracy: 0.8005 - val_loss: 0.5097 - val_accuracy: 0.8083\n",
            "Epoch 98/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5146 - accuracy: 0.8013 - val_loss: 0.5079 - val_accuracy: 0.8088\n",
            "Epoch 99/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5110 - accuracy: 0.8020 - val_loss: 0.5079 - val_accuracy: 0.8104\n",
            "Epoch 100/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5126 - accuracy: 0.8008 - val_loss: 0.5047 - val_accuracy: 0.8119\n",
            "Epoch 101/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5088 - accuracy: 0.8008 - val_loss: 0.5101 - val_accuracy: 0.8065\n",
            "Epoch 102/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5088 - accuracy: 0.8022 - val_loss: 0.5034 - val_accuracy: 0.8111\n",
            "Epoch 103/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5096 - accuracy: 0.8008 - val_loss: 0.5004 - val_accuracy: 0.8088\n",
            "Epoch 104/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5108 - accuracy: 0.8004 - val_loss: 0.5027 - val_accuracy: 0.8070\n",
            "Epoch 105/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5086 - accuracy: 0.7985 - val_loss: 0.5041 - val_accuracy: 0.8106\n",
            "Epoch 106/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5052 - accuracy: 0.8035 - val_loss: 0.5039 - val_accuracy: 0.8127\n",
            "Epoch 107/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5067 - accuracy: 0.7991 - val_loss: 0.4998 - val_accuracy: 0.8137\n",
            "Epoch 108/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5037 - accuracy: 0.8033 - val_loss: 0.5031 - val_accuracy: 0.8098\n",
            "Epoch 109/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5008 - accuracy: 0.8069 - val_loss: 0.5108 - val_accuracy: 0.8101\n",
            "Epoch 110/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5036 - accuracy: 0.8042 - val_loss: 0.5016 - val_accuracy: 0.8127\n",
            "Epoch 111/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5044 - accuracy: 0.8039 - val_loss: 0.5013 - val_accuracy: 0.8119\n",
            "Epoch 112/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5017 - accuracy: 0.8053 - val_loss: 0.4960 - val_accuracy: 0.8119\n",
            "Epoch 113/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5026 - accuracy: 0.8040 - val_loss: 0.4976 - val_accuracy: 0.8147\n",
            "Epoch 114/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4991 - accuracy: 0.8057 - val_loss: 0.4935 - val_accuracy: 0.8155\n",
            "Epoch 115/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4969 - accuracy: 0.8065 - val_loss: 0.5069 - val_accuracy: 0.8078\n",
            "Epoch 116/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4961 - accuracy: 0.8101 - val_loss: 0.4983 - val_accuracy: 0.8114\n",
            "Epoch 117/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4996 - accuracy: 0.8048 - val_loss: 0.4953 - val_accuracy: 0.8165\n",
            "Epoch 118/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4905 - accuracy: 0.8084 - val_loss: 0.4959 - val_accuracy: 0.8119\n",
            "Epoch 119/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4950 - accuracy: 0.8057 - val_loss: 0.4969 - val_accuracy: 0.8132\n",
            "Epoch 120/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4911 - accuracy: 0.8104 - val_loss: 0.5004 - val_accuracy: 0.8142\n",
            "Epoch 121/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4918 - accuracy: 0.8053 - val_loss: 0.4892 - val_accuracy: 0.8165\n",
            "Epoch 122/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4924 - accuracy: 0.8066 - val_loss: 0.4907 - val_accuracy: 0.8145\n",
            "Epoch 123/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4904 - accuracy: 0.8122 - val_loss: 0.4914 - val_accuracy: 0.8158\n",
            "Epoch 124/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4951 - accuracy: 0.8090 - val_loss: 0.4856 - val_accuracy: 0.8201\n",
            "Epoch 125/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4922 - accuracy: 0.8082 - val_loss: 0.4895 - val_accuracy: 0.8189\n",
            "Epoch 126/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4895 - accuracy: 0.8098 - val_loss: 0.4891 - val_accuracy: 0.8163\n",
            "Epoch 127/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4947 - accuracy: 0.8090 - val_loss: 0.4951 - val_accuracy: 0.8199\n",
            "Epoch 128/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4886 - accuracy: 0.8110 - val_loss: 0.4909 - val_accuracy: 0.8160\n",
            "Epoch 129/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4848 - accuracy: 0.8131 - val_loss: 0.4951 - val_accuracy: 0.8135\n",
            "Epoch 130/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4897 - accuracy: 0.8089 - val_loss: 0.4923 - val_accuracy: 0.8173\n",
            "Epoch 131/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4821 - accuracy: 0.8121 - val_loss: 0.4861 - val_accuracy: 0.8181\n",
            "Epoch 132/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4877 - accuracy: 0.8058 - val_loss: 0.4875 - val_accuracy: 0.8163\n",
            "Epoch 133/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4872 - accuracy: 0.8128 - val_loss: 0.4957 - val_accuracy: 0.8119\n",
            "Epoch 134/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4842 - accuracy: 0.8115 - val_loss: 0.4849 - val_accuracy: 0.8181\n",
            "Epoch 135/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4824 - accuracy: 0.8109 - val_loss: 0.4884 - val_accuracy: 0.8194\n",
            "Epoch 136/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4854 - accuracy: 0.8128 - val_loss: 0.4907 - val_accuracy: 0.8176\n",
            "Epoch 137/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4803 - accuracy: 0.8153 - val_loss: 0.4867 - val_accuracy: 0.8204\n",
            "Epoch 138/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4793 - accuracy: 0.8133 - val_loss: 0.4850 - val_accuracy: 0.8150\n",
            "Epoch 139/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4817 - accuracy: 0.8117 - val_loss: 0.4866 - val_accuracy: 0.8191\n",
            "Epoch 140/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4790 - accuracy: 0.8151 - val_loss: 0.4834 - val_accuracy: 0.8204\n",
            "Epoch 141/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4799 - accuracy: 0.8135 - val_loss: 0.4846 - val_accuracy: 0.8178\n",
            "Epoch 142/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4870 - accuracy: 0.8107 - val_loss: 0.4830 - val_accuracy: 0.8201\n",
            "Epoch 143/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4771 - accuracy: 0.8155 - val_loss: 0.4913 - val_accuracy: 0.8137\n",
            "Epoch 144/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4802 - accuracy: 0.8124 - val_loss: 0.4820 - val_accuracy: 0.8201\n",
            "Epoch 145/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4766 - accuracy: 0.8167 - val_loss: 0.4859 - val_accuracy: 0.8183\n",
            "Epoch 146/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4823 - accuracy: 0.8130 - val_loss: 0.4837 - val_accuracy: 0.8199\n",
            "Epoch 147/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4779 - accuracy: 0.8145 - val_loss: 0.4840 - val_accuracy: 0.8212\n",
            "Epoch 148/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4751 - accuracy: 0.8146 - val_loss: 0.4804 - val_accuracy: 0.8209\n",
            "Epoch 149/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4750 - accuracy: 0.8165 - val_loss: 0.4807 - val_accuracy: 0.8207\n",
            "Epoch 150/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4734 - accuracy: 0.8168 - val_loss: 0.4791 - val_accuracy: 0.8220\n",
            "Epoch 151/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4751 - accuracy: 0.8149 - val_loss: 0.4809 - val_accuracy: 0.8194\n",
            "Epoch 152/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4722 - accuracy: 0.8155 - val_loss: 0.4809 - val_accuracy: 0.8178\n",
            "Epoch 153/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4745 - accuracy: 0.8135 - val_loss: 0.4773 - val_accuracy: 0.8207\n",
            "Epoch 154/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4752 - accuracy: 0.8144 - val_loss: 0.4752 - val_accuracy: 0.8230\n",
            "Epoch 155/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4695 - accuracy: 0.8165 - val_loss: 0.4775 - val_accuracy: 0.8256\n",
            "Epoch 156/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4727 - accuracy: 0.8190 - val_loss: 0.4800 - val_accuracy: 0.8158\n",
            "Epoch 157/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4724 - accuracy: 0.8131 - val_loss: 0.4814 - val_accuracy: 0.8191\n",
            "Epoch 158/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4756 - accuracy: 0.8158 - val_loss: 0.4761 - val_accuracy: 0.8183\n",
            "Epoch 159/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4678 - accuracy: 0.8175 - val_loss: 0.4823 - val_accuracy: 0.8222\n",
            "Epoch 160/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4764 - accuracy: 0.8169 - val_loss: 0.4728 - val_accuracy: 0.8253\n",
            "Epoch 161/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4710 - accuracy: 0.8155 - val_loss: 0.4789 - val_accuracy: 0.8204\n",
            "Epoch 162/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4707 - accuracy: 0.8163 - val_loss: 0.4751 - val_accuracy: 0.8196\n",
            "Epoch 163/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4676 - accuracy: 0.8179 - val_loss: 0.4734 - val_accuracy: 0.8220\n",
            "Epoch 164/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4688 - accuracy: 0.8204 - val_loss: 0.4784 - val_accuracy: 0.8186\n",
            "Epoch 165/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4689 - accuracy: 0.8177 - val_loss: 0.4750 - val_accuracy: 0.8181\n",
            "Epoch 166/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4694 - accuracy: 0.8183 - val_loss: 0.4742 - val_accuracy: 0.8199\n",
            "Epoch 167/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4685 - accuracy: 0.8191 - val_loss: 0.4812 - val_accuracy: 0.8142\n",
            "Epoch 168/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4642 - accuracy: 0.8198 - val_loss: 0.4733 - val_accuracy: 0.8230\n",
            "Epoch 169/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4656 - accuracy: 0.8172 - val_loss: 0.4765 - val_accuracy: 0.8168\n",
            "Epoch 170/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4659 - accuracy: 0.8185 - val_loss: 0.4730 - val_accuracy: 0.8258\n",
            "Epoch 171/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4654 - accuracy: 0.8202 - val_loss: 0.4739 - val_accuracy: 0.8250\n",
            "Epoch 172/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4673 - accuracy: 0.8181 - val_loss: 0.4737 - val_accuracy: 0.8256\n",
            "Epoch 173/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4665 - accuracy: 0.8198 - val_loss: 0.4748 - val_accuracy: 0.8207\n",
            "Epoch 174/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4617 - accuracy: 0.8209 - val_loss: 0.4693 - val_accuracy: 0.8263\n",
            "Epoch 175/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4612 - accuracy: 0.8213 - val_loss: 0.4749 - val_accuracy: 0.8222\n",
            "Epoch 176/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4641 - accuracy: 0.8196 - val_loss: 0.4742 - val_accuracy: 0.8217\n",
            "Epoch 177/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4667 - accuracy: 0.8177 - val_loss: 0.4706 - val_accuracy: 0.8204\n",
            "Epoch 178/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4629 - accuracy: 0.8196 - val_loss: 0.4692 - val_accuracy: 0.8250\n",
            "Epoch 179/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4622 - accuracy: 0.8220 - val_loss: 0.4710 - val_accuracy: 0.8235\n",
            "Epoch 180/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4635 - accuracy: 0.8203 - val_loss: 0.4678 - val_accuracy: 0.8230\n",
            "Epoch 181/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4616 - accuracy: 0.8187 - val_loss: 0.4654 - val_accuracy: 0.8232\n",
            "Epoch 182/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4602 - accuracy: 0.8218 - val_loss: 0.4696 - val_accuracy: 0.8191\n",
            "Epoch 183/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4564 - accuracy: 0.8223 - val_loss: 0.4658 - val_accuracy: 0.8238\n",
            "Epoch 184/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4577 - accuracy: 0.8219 - val_loss: 0.4711 - val_accuracy: 0.8201\n",
            "Epoch 185/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4603 - accuracy: 0.8204 - val_loss: 0.4659 - val_accuracy: 0.8217\n",
            "Epoch 186/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4568 - accuracy: 0.8251 - val_loss: 0.4677 - val_accuracy: 0.8227\n",
            "Epoch 187/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4544 - accuracy: 0.8233 - val_loss: 0.4664 - val_accuracy: 0.8276\n",
            "Epoch 188/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4564 - accuracy: 0.8222 - val_loss: 0.4685 - val_accuracy: 0.8191\n",
            "Epoch 189/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4560 - accuracy: 0.8221 - val_loss: 0.4769 - val_accuracy: 0.8160\n",
            "Epoch 190/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4589 - accuracy: 0.8241 - val_loss: 0.4702 - val_accuracy: 0.8173\n",
            "Epoch 191/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4540 - accuracy: 0.8234 - val_loss: 0.4657 - val_accuracy: 0.8199\n",
            "Epoch 192/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4553 - accuracy: 0.8243 - val_loss: 0.4659 - val_accuracy: 0.8258\n",
            "Epoch 193/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4542 - accuracy: 0.8245 - val_loss: 0.4671 - val_accuracy: 0.8209\n",
            "Epoch 194/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4519 - accuracy: 0.8250 - val_loss: 0.4629 - val_accuracy: 0.8245\n",
            "Epoch 195/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4559 - accuracy: 0.8213 - val_loss: 0.4652 - val_accuracy: 0.8240\n",
            "Epoch 196/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4544 - accuracy: 0.8236 - val_loss: 0.4701 - val_accuracy: 0.8243\n",
            "Epoch 197/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4570 - accuracy: 0.8225 - val_loss: 0.4618 - val_accuracy: 0.8248\n",
            "Epoch 198/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4520 - accuracy: 0.8259 - val_loss: 0.4602 - val_accuracy: 0.8266\n",
            "Epoch 199/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4559 - accuracy: 0.8234 - val_loss: 0.4600 - val_accuracy: 0.8258\n",
            "Epoch 200/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4511 - accuracy: 0.8241 - val_loss: 0.4665 - val_accuracy: 0.8230\n",
            "Epoch 201/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4540 - accuracy: 0.8242 - val_loss: 0.4628 - val_accuracy: 0.8274\n",
            "Epoch 202/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4544 - accuracy: 0.8218 - val_loss: 0.4732 - val_accuracy: 0.8209\n",
            "Epoch 203/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4534 - accuracy: 0.8236 - val_loss: 0.4652 - val_accuracy: 0.8243\n",
            "Epoch 204/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4500 - accuracy: 0.8268 - val_loss: 0.4690 - val_accuracy: 0.8232\n",
            "Epoch 205/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4559 - accuracy: 0.8230 - val_loss: 0.4636 - val_accuracy: 0.8266\n",
            "Epoch 206/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4491 - accuracy: 0.8242 - val_loss: 0.4688 - val_accuracy: 0.8209\n",
            "Epoch 207/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4494 - accuracy: 0.8264 - val_loss: 0.4640 - val_accuracy: 0.8227\n",
            "Epoch 208/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4488 - accuracy: 0.8264 - val_loss: 0.4715 - val_accuracy: 0.8225\n",
            "Epoch 209/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4463 - accuracy: 0.8293 - val_loss: 0.4606 - val_accuracy: 0.8253\n",
            "Epoch 210/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4446 - accuracy: 0.8276 - val_loss: 0.4590 - val_accuracy: 0.8245\n",
            "Epoch 211/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4530 - accuracy: 0.8267 - val_loss: 0.4601 - val_accuracy: 0.8243\n",
            "Epoch 212/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4503 - accuracy: 0.8274 - val_loss: 0.4581 - val_accuracy: 0.8253\n",
            "Epoch 213/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4466 - accuracy: 0.8261 - val_loss: 0.4646 - val_accuracy: 0.8201\n",
            "Epoch 214/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4536 - accuracy: 0.8241 - val_loss: 0.4598 - val_accuracy: 0.8276\n",
            "Epoch 215/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4444 - accuracy: 0.8278 - val_loss: 0.4576 - val_accuracy: 0.8279\n",
            "Epoch 216/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4482 - accuracy: 0.8276 - val_loss: 0.4607 - val_accuracy: 0.8271\n",
            "Epoch 217/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4471 - accuracy: 0.8272 - val_loss: 0.4568 - val_accuracy: 0.8292\n",
            "Epoch 218/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4455 - accuracy: 0.8283 - val_loss: 0.4558 - val_accuracy: 0.8284\n",
            "Epoch 219/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4432 - accuracy: 0.8272 - val_loss: 0.4539 - val_accuracy: 0.8261\n",
            "Epoch 220/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4493 - accuracy: 0.8270 - val_loss: 0.4548 - val_accuracy: 0.8256\n",
            "Epoch 221/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4421 - accuracy: 0.8276 - val_loss: 0.4511 - val_accuracy: 0.8317\n",
            "Epoch 222/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4421 - accuracy: 0.8285 - val_loss: 0.4544 - val_accuracy: 0.8284\n",
            "Epoch 223/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4458 - accuracy: 0.8287 - val_loss: 0.4544 - val_accuracy: 0.8248\n",
            "Epoch 224/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4452 - accuracy: 0.8292 - val_loss: 0.4499 - val_accuracy: 0.8274\n",
            "Epoch 225/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4429 - accuracy: 0.8283 - val_loss: 0.4598 - val_accuracy: 0.8204\n",
            "Epoch 226/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4411 - accuracy: 0.8300 - val_loss: 0.4524 - val_accuracy: 0.8279\n",
            "Epoch 227/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4412 - accuracy: 0.8286 - val_loss: 0.4498 - val_accuracy: 0.8271\n",
            "Epoch 228/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4386 - accuracy: 0.8312 - val_loss: 0.4583 - val_accuracy: 0.8204\n",
            "Epoch 229/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4429 - accuracy: 0.8287 - val_loss: 0.4531 - val_accuracy: 0.8299\n",
            "Epoch 230/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4428 - accuracy: 0.8294 - val_loss: 0.4568 - val_accuracy: 0.8266\n",
            "Epoch 231/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4393 - accuracy: 0.8324 - val_loss: 0.4503 - val_accuracy: 0.8312\n",
            "Epoch 232/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4444 - accuracy: 0.8278 - val_loss: 0.4560 - val_accuracy: 0.8250\n",
            "Epoch 233/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4422 - accuracy: 0.8284 - val_loss: 0.4603 - val_accuracy: 0.8227\n",
            "Epoch 234/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4394 - accuracy: 0.8295 - val_loss: 0.4497 - val_accuracy: 0.8243\n",
            "Epoch 235/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4438 - accuracy: 0.8282 - val_loss: 0.4541 - val_accuracy: 0.8268\n",
            "Epoch 236/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4410 - accuracy: 0.8287 - val_loss: 0.4566 - val_accuracy: 0.8266\n",
            "Epoch 237/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4440 - accuracy: 0.8280 - val_loss: 0.4503 - val_accuracy: 0.8274\n",
            "Epoch 238/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4375 - accuracy: 0.8333 - val_loss: 0.4503 - val_accuracy: 0.8261\n",
            "Epoch 239/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4388 - accuracy: 0.8305 - val_loss: 0.4515 - val_accuracy: 0.8284\n",
            "Epoch 240/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4412 - accuracy: 0.8299 - val_loss: 0.4482 - val_accuracy: 0.8284\n",
            "Epoch 241/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4384 - accuracy: 0.8308 - val_loss: 0.4526 - val_accuracy: 0.8238\n",
            "Epoch 242/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4369 - accuracy: 0.8325 - val_loss: 0.4512 - val_accuracy: 0.8227\n",
            "Epoch 243/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4385 - accuracy: 0.8322 - val_loss: 0.4547 - val_accuracy: 0.8227\n",
            "Epoch 244/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4364 - accuracy: 0.8296 - val_loss: 0.4488 - val_accuracy: 0.8266\n",
            "Epoch 245/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4382 - accuracy: 0.8314 - val_loss: 0.4498 - val_accuracy: 0.8243\n",
            "Epoch 246/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4328 - accuracy: 0.8306 - val_loss: 0.4486 - val_accuracy: 0.8287\n",
            "Epoch 247/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4331 - accuracy: 0.8319 - val_loss: 0.4507 - val_accuracy: 0.8284\n",
            "Epoch 248/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4324 - accuracy: 0.8308 - val_loss: 0.4457 - val_accuracy: 0.8307\n",
            "Epoch 249/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4330 - accuracy: 0.8320 - val_loss: 0.4489 - val_accuracy: 0.8268\n",
            "Epoch 250/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4358 - accuracy: 0.8328 - val_loss: 0.4506 - val_accuracy: 0.8250\n",
            "Epoch 251/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4329 - accuracy: 0.8328 - val_loss: 0.4545 - val_accuracy: 0.8258\n",
            "Epoch 252/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4351 - accuracy: 0.8308 - val_loss: 0.4460 - val_accuracy: 0.8287\n",
            "Epoch 253/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4359 - accuracy: 0.8330 - val_loss: 0.4527 - val_accuracy: 0.8248\n",
            "Epoch 254/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4315 - accuracy: 0.8318 - val_loss: 0.4497 - val_accuracy: 0.8289\n",
            "Epoch 255/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4355 - accuracy: 0.8299 - val_loss: 0.4529 - val_accuracy: 0.8258\n",
            "Epoch 256/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4274 - accuracy: 0.8331 - val_loss: 0.4474 - val_accuracy: 0.8279\n",
            "Epoch 257/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4294 - accuracy: 0.8335 - val_loss: 0.4430 - val_accuracy: 0.8281\n",
            "Epoch 258/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4315 - accuracy: 0.8313 - val_loss: 0.4447 - val_accuracy: 0.8307\n",
            "Epoch 259/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4324 - accuracy: 0.8341 - val_loss: 0.4540 - val_accuracy: 0.8256\n",
            "Epoch 260/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4303 - accuracy: 0.8326 - val_loss: 0.4469 - val_accuracy: 0.8248\n",
            "Epoch 261/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4283 - accuracy: 0.8350 - val_loss: 0.4509 - val_accuracy: 0.8248\n",
            "Epoch 262/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4268 - accuracy: 0.8343 - val_loss: 0.4449 - val_accuracy: 0.8294\n",
            "Epoch 263/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4308 - accuracy: 0.8316 - val_loss: 0.4505 - val_accuracy: 0.8243\n",
            "Epoch 264/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4309 - accuracy: 0.8323 - val_loss: 0.4483 - val_accuracy: 0.8261\n",
            "Epoch 265/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4285 - accuracy: 0.8367 - val_loss: 0.4447 - val_accuracy: 0.8274\n",
            "Epoch 266/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4327 - accuracy: 0.8339 - val_loss: 0.4456 - val_accuracy: 0.8279\n",
            "Epoch 267/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4279 - accuracy: 0.8347 - val_loss: 0.4442 - val_accuracy: 0.8281\n",
            "Epoch 268/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4282 - accuracy: 0.8323 - val_loss: 0.4493 - val_accuracy: 0.8253\n",
            "Epoch 269/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4236 - accuracy: 0.8377 - val_loss: 0.4437 - val_accuracy: 0.8330\n",
            "Epoch 270/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4277 - accuracy: 0.8378 - val_loss: 0.4464 - val_accuracy: 0.8268\n",
            "Epoch 271/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4309 - accuracy: 0.8338 - val_loss: 0.4475 - val_accuracy: 0.8263\n",
            "Epoch 272/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4225 - accuracy: 0.8379 - val_loss: 0.4384 - val_accuracy: 0.8297\n",
            "Epoch 273/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4259 - accuracy: 0.8339 - val_loss: 0.4490 - val_accuracy: 0.8294\n",
            "Epoch 274/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4313 - accuracy: 0.8350 - val_loss: 0.4428 - val_accuracy: 0.8263\n",
            "Epoch 275/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4262 - accuracy: 0.8339 - val_loss: 0.4411 - val_accuracy: 0.8263\n",
            "Epoch 276/400\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4242 - accuracy: 0.8335 - val_loss: 0.4417 - val_accuracy: 0.8299\n",
            "Epoch 277/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4254 - accuracy: 0.8366 - val_loss: 0.4444 - val_accuracy: 0.8268\n",
            "Epoch 278/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4223 - accuracy: 0.8395 - val_loss: 0.4464 - val_accuracy: 0.8258\n",
            "Epoch 279/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4289 - accuracy: 0.8346 - val_loss: 0.4474 - val_accuracy: 0.8256\n",
            "Epoch 280/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4254 - accuracy: 0.8381 - val_loss: 0.4460 - val_accuracy: 0.8297\n",
            "Epoch 281/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4231 - accuracy: 0.8367 - val_loss: 0.4411 - val_accuracy: 0.8292\n",
            "Epoch 282/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4287 - accuracy: 0.8335 - val_loss: 0.4480 - val_accuracy: 0.8256\n",
            "Epoch 283/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4243 - accuracy: 0.8369 - val_loss: 0.4469 - val_accuracy: 0.8222\n",
            "Epoch 284/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4234 - accuracy: 0.8363 - val_loss: 0.4491 - val_accuracy: 0.8189\n",
            "Epoch 285/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4222 - accuracy: 0.8378 - val_loss: 0.4375 - val_accuracy: 0.8289\n",
            "Epoch 286/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4249 - accuracy: 0.8351 - val_loss: 0.4369 - val_accuracy: 0.8323\n",
            "Epoch 287/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4270 - accuracy: 0.8349 - val_loss: 0.4427 - val_accuracy: 0.8266\n",
            "Epoch 288/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4229 - accuracy: 0.8350 - val_loss: 0.4394 - val_accuracy: 0.8266\n",
            "Epoch 289/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4250 - accuracy: 0.8340 - val_loss: 0.4392 - val_accuracy: 0.8261\n",
            "Epoch 290/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4234 - accuracy: 0.8360 - val_loss: 0.4355 - val_accuracy: 0.8315\n",
            "Epoch 291/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4215 - accuracy: 0.8376 - val_loss: 0.4374 - val_accuracy: 0.8276\n",
            "Epoch 292/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4229 - accuracy: 0.8372 - val_loss: 0.4398 - val_accuracy: 0.8281\n",
            "Epoch 293/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4212 - accuracy: 0.8351 - val_loss: 0.4455 - val_accuracy: 0.8243\n",
            "Epoch 294/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4211 - accuracy: 0.8382 - val_loss: 0.4418 - val_accuracy: 0.8281\n",
            "Epoch 295/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4169 - accuracy: 0.8369 - val_loss: 0.4381 - val_accuracy: 0.8266\n",
            "Epoch 296/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4237 - accuracy: 0.8357 - val_loss: 0.4414 - val_accuracy: 0.8245\n",
            "Epoch 297/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4250 - accuracy: 0.8341 - val_loss: 0.4378 - val_accuracy: 0.8299\n",
            "Epoch 298/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4153 - accuracy: 0.8407 - val_loss: 0.4332 - val_accuracy: 0.8305\n",
            "Epoch 299/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4196 - accuracy: 0.8374 - val_loss: 0.4474 - val_accuracy: 0.8220\n",
            "Epoch 300/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4218 - accuracy: 0.8364 - val_loss: 0.4390 - val_accuracy: 0.8276\n",
            "Epoch 301/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4194 - accuracy: 0.8363 - val_loss: 0.4350 - val_accuracy: 0.8312\n",
            "Epoch 302/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4231 - accuracy: 0.8359 - val_loss: 0.4356 - val_accuracy: 0.8307\n",
            "Epoch 303/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4177 - accuracy: 0.8386 - val_loss: 0.4357 - val_accuracy: 0.8323\n",
            "Epoch 304/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4172 - accuracy: 0.8383 - val_loss: 0.4347 - val_accuracy: 0.8305\n",
            "Epoch 305/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4170 - accuracy: 0.8390 - val_loss: 0.4344 - val_accuracy: 0.8346\n",
            "Epoch 306/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4202 - accuracy: 0.8369 - val_loss: 0.4384 - val_accuracy: 0.8271\n",
            "Epoch 307/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4197 - accuracy: 0.8383 - val_loss: 0.4405 - val_accuracy: 0.8256\n",
            "Epoch 308/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4160 - accuracy: 0.8368 - val_loss: 0.4349 - val_accuracy: 0.8294\n",
            "Epoch 309/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4166 - accuracy: 0.8388 - val_loss: 0.4315 - val_accuracy: 0.8287\n",
            "Epoch 310/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4132 - accuracy: 0.8421 - val_loss: 0.4280 - val_accuracy: 0.8343\n",
            "Epoch 311/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4165 - accuracy: 0.8417 - val_loss: 0.4316 - val_accuracy: 0.8351\n",
            "Epoch 312/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4172 - accuracy: 0.8401 - val_loss: 0.4296 - val_accuracy: 0.8354\n",
            "Epoch 313/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4170 - accuracy: 0.8388 - val_loss: 0.4329 - val_accuracy: 0.8330\n",
            "Epoch 314/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4169 - accuracy: 0.8400 - val_loss: 0.4362 - val_accuracy: 0.8348\n",
            "Epoch 315/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4179 - accuracy: 0.8384 - val_loss: 0.4336 - val_accuracy: 0.8258\n",
            "Epoch 316/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4138 - accuracy: 0.8433 - val_loss: 0.4306 - val_accuracy: 0.8330\n",
            "Epoch 317/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4166 - accuracy: 0.8402 - val_loss: 0.4334 - val_accuracy: 0.8320\n",
            "Epoch 318/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4155 - accuracy: 0.8405 - val_loss: 0.4329 - val_accuracy: 0.8302\n",
            "Epoch 319/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4151 - accuracy: 0.8414 - val_loss: 0.4371 - val_accuracy: 0.8289\n",
            "Epoch 320/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4140 - accuracy: 0.8412 - val_loss: 0.4350 - val_accuracy: 0.8325\n",
            "Epoch 321/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4113 - accuracy: 0.8401 - val_loss: 0.4343 - val_accuracy: 0.8289\n",
            "Epoch 322/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4100 - accuracy: 0.8411 - val_loss: 0.4309 - val_accuracy: 0.8341\n",
            "Epoch 323/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4123 - accuracy: 0.8408 - val_loss: 0.4350 - val_accuracy: 0.8323\n",
            "Epoch 324/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4099 - accuracy: 0.8408 - val_loss: 0.4383 - val_accuracy: 0.8294\n",
            "Epoch 325/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4152 - accuracy: 0.8378 - val_loss: 0.4312 - val_accuracy: 0.8294\n",
            "Epoch 326/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4125 - accuracy: 0.8406 - val_loss: 0.4313 - val_accuracy: 0.8317\n",
            "Epoch 327/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4107 - accuracy: 0.8435 - val_loss: 0.4386 - val_accuracy: 0.8279\n",
            "Epoch 328/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4129 - accuracy: 0.8417 - val_loss: 0.4313 - val_accuracy: 0.8305\n",
            "Epoch 329/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4131 - accuracy: 0.8410 - val_loss: 0.4342 - val_accuracy: 0.8312\n",
            "Epoch 330/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4112 - accuracy: 0.8411 - val_loss: 0.4268 - val_accuracy: 0.8346\n",
            "Epoch 331/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4150 - accuracy: 0.8399 - val_loss: 0.4369 - val_accuracy: 0.8271\n",
            "Epoch 332/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4134 - accuracy: 0.8401 - val_loss: 0.4352 - val_accuracy: 0.8276\n",
            "Epoch 333/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4102 - accuracy: 0.8413 - val_loss: 0.4377 - val_accuracy: 0.8312\n",
            "Epoch 334/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4100 - accuracy: 0.8413 - val_loss: 0.4363 - val_accuracy: 0.8258\n",
            "Epoch 335/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4102 - accuracy: 0.8417 - val_loss: 0.4269 - val_accuracy: 0.8390\n",
            "Epoch 336/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4035 - accuracy: 0.8431 - val_loss: 0.4359 - val_accuracy: 0.8266\n",
            "Epoch 337/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4076 - accuracy: 0.8430 - val_loss: 0.4297 - val_accuracy: 0.8348\n",
            "Epoch 338/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4109 - accuracy: 0.8446 - val_loss: 0.4287 - val_accuracy: 0.8320\n",
            "Epoch 339/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4083 - accuracy: 0.8444 - val_loss: 0.4300 - val_accuracy: 0.8317\n",
            "Epoch 340/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4127 - accuracy: 0.8398 - val_loss: 0.4315 - val_accuracy: 0.8292\n",
            "Epoch 341/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4087 - accuracy: 0.8431 - val_loss: 0.4274 - val_accuracy: 0.8341\n",
            "Epoch 342/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4061 - accuracy: 0.8457 - val_loss: 0.4251 - val_accuracy: 0.8361\n",
            "Epoch 343/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4139 - accuracy: 0.8384 - val_loss: 0.4300 - val_accuracy: 0.8315\n",
            "Epoch 344/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4078 - accuracy: 0.8431 - val_loss: 0.4281 - val_accuracy: 0.8351\n",
            "Epoch 345/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4098 - accuracy: 0.8403 - val_loss: 0.4332 - val_accuracy: 0.8276\n",
            "Epoch 346/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4112 - accuracy: 0.8406 - val_loss: 0.4254 - val_accuracy: 0.8325\n",
            "Epoch 347/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4117 - accuracy: 0.8416 - val_loss: 0.4304 - val_accuracy: 0.8287\n",
            "Epoch 348/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4065 - accuracy: 0.8424 - val_loss: 0.4284 - val_accuracy: 0.8323\n",
            "Epoch 349/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4041 - accuracy: 0.8446 - val_loss: 0.4313 - val_accuracy: 0.8292\n",
            "Epoch 350/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4100 - accuracy: 0.8433 - val_loss: 0.4238 - val_accuracy: 0.8372\n",
            "Epoch 351/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4074 - accuracy: 0.8412 - val_loss: 0.4221 - val_accuracy: 0.8372\n",
            "Epoch 352/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4070 - accuracy: 0.8431 - val_loss: 0.4260 - val_accuracy: 0.8312\n",
            "Epoch 353/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4090 - accuracy: 0.8430 - val_loss: 0.4268 - val_accuracy: 0.8372\n",
            "Epoch 354/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4059 - accuracy: 0.8437 - val_loss: 0.4230 - val_accuracy: 0.8372\n",
            "Epoch 355/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4039 - accuracy: 0.8421 - val_loss: 0.4225 - val_accuracy: 0.8374\n",
            "Epoch 356/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4073 - accuracy: 0.8411 - val_loss: 0.4304 - val_accuracy: 0.8338\n",
            "Epoch 357/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4044 - accuracy: 0.8442 - val_loss: 0.4233 - val_accuracy: 0.8377\n",
            "Epoch 358/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4021 - accuracy: 0.8442 - val_loss: 0.4245 - val_accuracy: 0.8312\n",
            "Epoch 359/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4105 - accuracy: 0.8421 - val_loss: 0.4224 - val_accuracy: 0.8397\n",
            "Epoch 360/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4081 - accuracy: 0.8433 - val_loss: 0.4279 - val_accuracy: 0.8333\n",
            "Epoch 361/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4062 - accuracy: 0.8429 - val_loss: 0.4221 - val_accuracy: 0.8366\n",
            "Epoch 362/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4040 - accuracy: 0.8440 - val_loss: 0.4302 - val_accuracy: 0.8333\n",
            "Epoch 363/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4076 - accuracy: 0.8422 - val_loss: 0.4280 - val_accuracy: 0.8364\n",
            "Epoch 364/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4038 - accuracy: 0.8454 - val_loss: 0.4252 - val_accuracy: 0.8348\n",
            "Epoch 365/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4084 - accuracy: 0.8408 - val_loss: 0.4253 - val_accuracy: 0.8356\n",
            "Epoch 366/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4017 - accuracy: 0.8439 - val_loss: 0.4208 - val_accuracy: 0.8382\n",
            "Epoch 367/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4075 - accuracy: 0.8433 - val_loss: 0.4240 - val_accuracy: 0.8374\n",
            "Epoch 368/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4025 - accuracy: 0.8444 - val_loss: 0.4233 - val_accuracy: 0.8333\n",
            "Epoch 369/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4048 - accuracy: 0.8430 - val_loss: 0.4221 - val_accuracy: 0.8359\n",
            "Epoch 370/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4043 - accuracy: 0.8440 - val_loss: 0.4208 - val_accuracy: 0.8366\n",
            "Epoch 371/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4023 - accuracy: 0.8451 - val_loss: 0.4188 - val_accuracy: 0.8431\n",
            "Epoch 372/400\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4015 - accuracy: 0.8438 - val_loss: 0.4234 - val_accuracy: 0.8354\n",
            "Epoch 373/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4008 - accuracy: 0.8437 - val_loss: 0.4229 - val_accuracy: 0.8356\n",
            "Epoch 374/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4009 - accuracy: 0.8442 - val_loss: 0.4188 - val_accuracy: 0.8379\n",
            "Epoch 375/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3968 - accuracy: 0.8495 - val_loss: 0.4302 - val_accuracy: 0.8289\n",
            "Epoch 376/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4001 - accuracy: 0.8470 - val_loss: 0.4186 - val_accuracy: 0.8392\n",
            "Epoch 377/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3971 - accuracy: 0.8447 - val_loss: 0.4286 - val_accuracy: 0.8299\n",
            "Epoch 378/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3989 - accuracy: 0.8465 - val_loss: 0.4234 - val_accuracy: 0.8335\n",
            "Epoch 379/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4050 - accuracy: 0.8432 - val_loss: 0.4186 - val_accuracy: 0.8379\n",
            "Epoch 380/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4012 - accuracy: 0.8442 - val_loss: 0.4193 - val_accuracy: 0.8400\n",
            "Epoch 381/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4005 - accuracy: 0.8478 - val_loss: 0.4180 - val_accuracy: 0.8431\n",
            "Epoch 382/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3980 - accuracy: 0.8457 - val_loss: 0.4323 - val_accuracy: 0.8274\n",
            "Epoch 383/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3974 - accuracy: 0.8469 - val_loss: 0.4170 - val_accuracy: 0.8372\n",
            "Epoch 384/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3957 - accuracy: 0.8473 - val_loss: 0.4209 - val_accuracy: 0.8348\n",
            "Epoch 385/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.4011 - accuracy: 0.8468 - val_loss: 0.4209 - val_accuracy: 0.8343\n",
            "Epoch 386/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3998 - accuracy: 0.8453 - val_loss: 0.4189 - val_accuracy: 0.8374\n",
            "Epoch 387/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3957 - accuracy: 0.8482 - val_loss: 0.4204 - val_accuracy: 0.8369\n",
            "Epoch 388/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3983 - accuracy: 0.8459 - val_loss: 0.4257 - val_accuracy: 0.8343\n",
            "Epoch 389/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3968 - accuracy: 0.8474 - val_loss: 0.4203 - val_accuracy: 0.8348\n",
            "Epoch 390/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3989 - accuracy: 0.8465 - val_loss: 0.4198 - val_accuracy: 0.8418\n",
            "Epoch 391/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3960 - accuracy: 0.8464 - val_loss: 0.4162 - val_accuracy: 0.8433\n",
            "Epoch 392/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.4005 - accuracy: 0.8441 - val_loss: 0.4185 - val_accuracy: 0.8387\n",
            "Epoch 393/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3933 - accuracy: 0.8510 - val_loss: 0.4198 - val_accuracy: 0.8374\n",
            "Epoch 394/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3974 - accuracy: 0.8483 - val_loss: 0.4229 - val_accuracy: 0.8351\n",
            "Epoch 395/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3974 - accuracy: 0.8449 - val_loss: 0.4183 - val_accuracy: 0.8366\n",
            "Epoch 396/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3953 - accuracy: 0.8466 - val_loss: 0.4236 - val_accuracy: 0.8328\n",
            "Epoch 397/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3951 - accuracy: 0.8466 - val_loss: 0.4236 - val_accuracy: 0.8335\n",
            "Epoch 398/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3903 - accuracy: 0.8504 - val_loss: 0.4241 - val_accuracy: 0.8330\n",
            "Epoch 399/400\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.3956 - accuracy: 0.8480 - val_loss: 0.4184 - val_accuracy: 0.8379\n",
            "Epoch 400/400\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3967 - accuracy: 0.8466 - val_loss: 0.4192 - val_accuracy: 0.8382\n"
          ]
        }
      ],
      "source": [
        "epochs = 400\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J4ANguLoDSg"
      },
      "outputs": [],
      "source": [
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "y_acc = history.history['accuracy']\n",
        "y_vacc = history.history['val_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ6ilJxKjZID",
        "outputId": "5fa712cf-6e0e-48dd-d480-124c1d659786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8433393239974976\n"
          ]
        }
      ],
      "source": [
        "print(max(y_vacc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7zwLxVoF-dW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5cd8aba3-b8fd-4a5c-cb6b-28abd902b395"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.plot(np.arange(len(y_vloss)), y_vloss, marker='.', c='red')\n",
        "ax1.plot(np.arange(len(y_loss)), y_loss, marker='.', c='blue')\n",
        "ax1.grid()\n",
        "plt.setp(ax1, xlabel='epoch', ylabel='loss')\n",
        "\n",
        "ax2.plot(np.arange(len(y_vacc)), y_vacc, marker='.', c='red')\n",
        "ax2.plot(np.arange(len(y_acc)), y_acc, marker='.', c='blue')\n",
        "ax2.grid()\n",
        "plt.setp(ax2, xlabel='epoch', ylabel='accuracy')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vIVZlTPr6s-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd07587-926a-4a05-c86e-1278525447c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3881,)\n",
            "(3881, 69, 69, 3)\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(val_ds)\n",
        "cs = np.argmax(preds, axis=1)\n",
        "print(cs.shape)\n",
        "print(val_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTqSOkB2so43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d8363de-b709-4c2f-de19-fe7f33ba5b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for idx, i in enumerate(cs):\n",
        "  if(i!= 4): continue\n",
        "  img = val_img[idx]\n",
        "  plt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "astro-class-galaxy10-newcnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}